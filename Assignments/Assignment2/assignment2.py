# -*- coding: utf-8 -*-
"""Copy of BBM409_PA2_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hJGYEna1ujy7xXtG6X46JSVfUvNMJO0Q
"""



"""### ## BBM 409 - Programming Assignment 2

* You can add as many cells as you want in-between each question.
* Please add comments to your code to explain your work.  

* Please be careful about the order of runs of cells. Doing the homework, it is likely that you will be running the cells in different orders, however, they will be evaluated in the order they appear. Hence, please try running the cells in this order before submission to make sure they work.    
* Please refer to the homework text for any implementation detail. You should also carefully review the steps explained here.
* This document is also your report. Show your work.

```
# This is formatted as code
```

# Mert Can Köseoğlu 2220356055

# 1. LOGISTIC REGRESSION TASK (40 points)

### 1. Data Loading and Exploration

##### Download the Bank Marketing dataset from https://drive.google.com/file/d/1t6QAtqfYLMhvv_XUnG4D_UsJcSwgF4an/view?usp=sharing  import other necessary libraries
"""

import pandas as pd
import numpy as np


# Load the dataset
df = pd.read_csv("portuguese_bank_marketing_numeric_random_subsampled.csv", encoding="utf-8")

# Display basic information about the dataset
print("Dataset Info:")
print(df.info())

# Display the first few rows of the dataset
print("\nFirst Few Rows:")
print(df.head())

# Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

"""### 2. calculate correlation between target variable 'y' and other features (5 points)"""

# Calculate the correlation of all features with the target variable 'y'
correlations = df.corr()['y'].sort_values(ascending=True)

# Display the correlations
print("Correlation with Target Variable 'y':")
print(correlations)

"""# 1.1 Implementing Logistic Regression with most correlated 2 features

###  Choose the two most correlated features with target feature 'y'
"""

X= df[["duration", "poutcome"]]
y= df['y'] -1

"""###  * Define your logistic regression model as class without using any built-in libraries
### * Define necessary functions such as sigmoid, fit, predict  (10 points)
"""

class LogisticRegression:
    def __init__(self, learning_rate=0.01, iterations=1000):
        self.learning_rate = learning_rate
        self.iterations = iterations
        self.weights = None
        self.bias = None

    def sigmoid(self, z):
        # Sigmoid activation function
        return 1 / (1 + np.exp(-z))

    def fit(self, X, y):
        # Initialize weights and bias
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        # Gradient descent
        for _ in range(self.iterations):
            # Linear model
            linear_model = np.dot(X, self.weights) + self.bias
            y_predicted = self.sigmoid(linear_model)

            # Compute gradients
            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)

            # Update weights and bias
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db

    def predict_proba(self, X):
        # Predict probabilities
        linear_model = np.dot(X, self.weights) + self.bias
        return self.sigmoid(linear_model)

    def predict(self, X):
        # Predict binary class labels
        y_predicted = self.predict_proba(X)
        return [1 if i > 0.5 else 0 for i in y_predicted]

"""Split the dataset into a training set and a validation set (80% training and 20% validation)."""

from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Check the shapes of the splits
print("Training set shape (X):", X_train.shape)
print("Training set shape (y):", y_train.shape)
print("Validation set shape (X):", X_val.shape)
print("Validation set shape (y):", y_val.shape)

"""Scale the features using StandardScaler"""

from sklearn.preprocessing import StandardScaler

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and validation sets
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

# Check a few samples from the scaled data
print("Range of scaled training features:\n", X_train_scaled[:5])
print("Range of scaled validation features:\n", X_val_scaled[:5])

"""* Initialize and train the custom logistic regression model"""

# Initialize the logistic regression model
model = LogisticRegression(learning_rate=0.01, iterations=1000)

# Train the model on the training set
model.fit(X_train_scaled, y_train)

# Output the learned weights and bias
print("Trained Weights:", model.weights)
print("Trained Bias:", model.bias)

"""* Make predictions on the validation set"""

# Make predictions on the validation set
y_pred = model.predict(X_val_scaled)

# Display the first few predictions
print("Predicted Labels:", y_pred[:10])
print("Actual Labels:", y_val[:10].values)

"""### Evaluate the model's performance, print classification report and confusion matrix  (5 points)"""

# Assuming y_val (actual labels) and y_pred (predicted labels) are defined
def evaluate_classification(y_true, y_pred):
    # Initialize confusion matrix values
    TP = FP = FN = TN = 0

    # Calculate confusion matrix values
    for pred, actual in zip(y_pred, y_true):
        if pred == 1 and actual == 1:
            TP += 1
        elif pred == 1 and actual == 0:
            FP += 1
        elif pred == 0 and actual == 1:
            FN += 1
        elif pred == 0 and actual == 0:
            TN += 1

    # Create confusion matrix
    confusion_matrix = [[TP, FP], [FN, TN]]

    # Calculate metrics
    accuracy = (TP + TN) / (TP + FP + FN + TN)
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

    # Print results
    print("Confusion Matrix:")
    print(f"[[{confusion_matrix[0][0]} {confusion_matrix[0][1]}]]")
    print(f"[[{confusion_matrix[1][0]} {confusion_matrix[1][1]}]]\n")

    print("Classification Report:")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1_score:.4f}")
    print(f"Accuracy: {accuracy:.4f}\n")


evaluate_classification(y_val, y_pred)

"""### Print decision boundaries as in PA1 (5 points)"""

import matplotlib.pyplot as plt

# Define a grid of points covering the feature space
x_min, x_max = X_train_scaled[:, 0].min() - 1, X_train_scaled[:, 0].max() + 1
y_min, y_max = X_train_scaled[:, 1].min() - 1, X_train_scaled[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))

# Predict the probabilities for each point in the grid
grid_points = np.c_[xx.ravel(), yy.ravel()]
Z = np.array(model.predict(grid_points))
Z = Z.reshape(xx.shape)

# Plot the decision boundary
plt.figure(figsize=(10, 6))
plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)
plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, edgecolor='k', cmap=plt.cm.Paired)
plt.title("Decision Boundary")
plt.xlabel("Duration (scaled)")
plt.ylabel("Poutcome (scaled)")
plt.colorbar(label='Class')
plt.show()

"""# 1.2 Implementing Logistic Regression using all features.

1.   Liste öğesi
2.   Liste öğesi

* Redefine input and target variables. In this experiment, you will use all input features in the dataset.
"""

X = df.drop(columns=['y'])
y = df['y']-1

"""* Split the dataset into a training set and a validation set (80% training and 20% validation)."""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""* Scale the features using StandardScaler"""

scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and validation sets
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

"""### Initialize and train the custom logistic regression model."""

model = LogisticRegression(learning_rate=0.01, iterations=1000)

# Train the model using the scaled training data
model.fit(X_train_scaled, y_train)

# Print the learned weights and bias
print("Learned Weights:", model.weights)
print("Learned Bias:", model.bias)

"""* Make predictions on the validation set"""

y_pred = model.predict(X_val_scaled)

# Display the first few predictions
print("Predicted Labels:", y_pred[:10])
print("Actual Labels:", y_val[:10].values)

"""### Evaluate the model's performance, print classification report and confusion matrix  (5 points)"""

evaluate_classification(y_val, y_pred)

"""### Briefly explain the impact of the number of features on the learning ability of the model. (5 points)

The number of features in a dataset can significantly affect the learning ability of a model. When there are too many features, the model may face the curse of dimensionality, where the data becomes sparse, leading to overfitting.

The study suggests that using all features in a dataset improves learning ability and performance by providing a comprehensive view of the data while using only the two most correlated features reduces dimensionality and may omit important predictors, emphasizing the importance of balancing feature selection.

### After completing the SVM and logistic regression tasks, the best results of the experiments with the SVM and Logistic regression models will be compared in a table. (5 points)

Model               | Features Used          | Accuracy | Precision | Recall | F1 Score
--------------------|------------------------|----------|-----------|--------|---------
Logistic Regression | Two Most Correlated   | 0.7561   | 0.8004    | 0.6824 | 0.7367
                    | All Features          | 0.8010   | 0.8132    | 0.7817 | 0.7971
SVM                 | All Features          | 0.8200   | 0.7900    | 0.8500 | 0.8200
                    | Two Most Correlated   | 0.7600   | 0.7700    | 0.7300 | 0.7500
                    | Two Least Correlated  | 0.6000   | 0.6200    | 0.4300 | 0.5100


- Using all features consistently outperformed using only two most or two least correlated features.

- Logistic regression had better performance with all features compared to just the two most correlated ones.

- SVM achieved the highest accuracy with all features but struggled significantly with the two least correlated features, highlighting the importance of feature relevance in SVM models.

# 2. Support Vector Machine Task  (30 points)

* Define your SVM model using sklearn

## 2.1 implementing svm with grid search cv using all features (10 points)

* Define features and target variable, you will use all features of dataset in this task
"""

from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

X = df.drop(columns=['y'])
y = df['y']-1

"""* Split the dataset into a training set and a validation set (80% training and 20% validation)."""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""* Scale the features using StandardScaler"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

"""#### Implement GridSearchCV  (5 points)"""

param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto', 0.1]
}

"""* Initialize the SVM classifier"""

svm = SVC()

"""* Train the SVM classifier with the best parameters found from grid search

"""

# Initialize GridSearchCV with the SVM model and parameter grid
grid_search = GridSearchCV(estimator=svm, param_grid=param_grid,
                           cv=5, n_jobs=-1, verbose=1, scoring='accuracy')
# Fit the GridSearchCV to the training data
grid_search.fit(X_train_scaled, y_train)

# Print the best parameters found by GridSearchCV
best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f"Best Hyperparameters: {best_params}")
print(f"Best Cross-Validation Accuracy: {best_score:.4f}")

"""* Make predictions on the validation set using the best model

"""

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_val_scaled)
print("Predictions: ", y_pred[:10])

"""#### Evaluate the model's performance, print classification report and confusion matrix and best parameters found from GridSearchCV  (5 points)"""

print(f"Best Hyperparameters: {best_params}")

# Print confusion matrix and classification report
conf_matrix = confusion_matrix(y_val, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

print("\nClassification Report:")
print(classification_report(y_val, y_pred))

"""## 2.2 implementing svm with most correlated 2 features (10 points)

#### Choose the two most correlated features with target feature 'y'
"""

X = df[['duration', 'poutcome']]
y = df['y'] - 1

"""* Split the dataset into a training set and a validation set (80% training and 20% validation)."""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""* Scale the features using StandardScaler"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

"""*  Initialize the SVM classifier, assign 'C' and 'kernel' parameters from the best hyperparameters you found from GridSearchCV"""

svm = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'])

print("SVM initialized with best parameters:", best_params)

"""* Train the SVM classifier"""

svm.fit(X_train_scaled, y_train)

train_accuracy = svm.score(X_train_scaled, y_train)
print(f"Training Accuracy: ", train_accuracy)

"""* Make predictions on the validation set"""

y_pred = svm.predict(X_val_scaled)

print("Predictions: ", y_pred[:10])

"""#### Evaluate the model's performance, print classification report and confusion matrix  (5 points)"""

# Evaluate the model
conf_matrix = confusion_matrix(y_val, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

print("\nClassification Report:")
print(classification_report(y_val, y_pred))

"""##### Visualize decision boundary and support vectors (5 points)"""

# Create a meshgrid for plotting
x_min, x_max = X_train_scaled[:, 0].min() - 1, X_train_scaled[:, 0].max() + 1
y_min, y_max = X_train_scaled[:, 1].min() - 1, X_train_scaled[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                     np.arange(y_min, y_max, 0.01))

# Predict for the grid points
Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the decision boundary
plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)
plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, s=20, edgecolor='k', cmap=plt.cm.coolwarm)
plt.title("SVM Decision Boundary with Support Vectors")
plt.xlabel("Duration (scaled)")
plt.ylabel("Poutcome (scaled)")

# Highlight support vectors
plt.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1], s=100, facecolors='none', edgecolors='k', label='Support Vectors')
plt.legend()
plt.show()

"""## 2.3 implementing svm with least correlated 2 features (10 points)

#### Choose the two least correlated features with target feature 'y'
"""

# Select the two least correlated features
X= df[["job", "month"]]
y= df['y'] -1

"""* Split the dataset into a training set and a validation set (80% training and 20% validation)."""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""* Scale the features using StandardScaler"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

"""*  Initialize the SVM classifier, assign 'C' and 'kernel' parameters from the best hyperparameters you found from GridSearchCV"""

svm = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'])

print("SVM initialized with best parameters:", best_params)

"""* Train the SVM classifier"""

svm.fit(X_train_scaled, y_train)

train_accuracy = svm.score(X_train_scaled, y_train)
print(f"Training Accuracy: ", train_accuracy)

"""* Make predictions on the validation set"""

y_pred = svm.predict(X_val_scaled)

print("Predictions: ", y_pred[:10])

"""#### Evaluate the model's performance, print classification report and confusion matrix  (5 points)"""

# Evaluate the model
conf_matrix = confusion_matrix(y_val, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

print("\nClassification Report:")
print(classification_report(y_val, y_pred))

"""##### Visualize decision boundary and support vectors(5 points)"""

# Create a meshgrid for plotting
x_min, x_max = X_train_scaled[:, 0].min() - 1, X_train_scaled[:, 0].max() + 1
y_min, y_max = X_train_scaled[:, 1].min() - 1, X_train_scaled[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                     np.arange(y_min, y_max, 0.01))

# Predict for the grid points
Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the decision boundary
plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)
plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, s=20, edgecolor='k', cmap=plt.cm.coolwarm)
plt.title("SVM Decision Boundary with Support Vectors")
plt.xlabel("Job (scaled)")
plt.ylabel("Month (scaled)")

# Highlight support vectors
plt.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1], s=100, facecolors='none', edgecolors='k', label='Support Vectors')
plt.legend()
plt.show()

"""# 3. Decision Tree Task (30 points)

* Define your decision tree model using sklearn. Also you should define other necessary modules for visualize the decision tree

### Download the dataset from https://drive.google.com/file/d/1D3peA-TzIqJqZDDKTlK0GQ7Ya6FIemFv/view?usp=sharing

### import other necessary libraries
"""

df=pd.read_csv("weights_bmi_6classes_updated.csv", encoding="utf-8")
print(df.head())

"""* Define features and target variable, you will use all features of dataset in this task"""

X = df.drop(columns=['FLAG'])
y = df['FLAG']

print(X.head())
print(y.head())

"""* Split the dataset into a training set and a validation set (80% training and 20% validation)."""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""* Initialize the Decision Tree classifier"""

from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree

decision_tree = DecisionTreeClassifier(random_state=42)

"""* Train the Decision Tree classifier"""

decision_tree.fit(X_train, y_train)

train_accuracy = decision_tree.score(X_train, y_train)
print(f"Training Accuracy: ", train_accuracy)

"""* Make predictions on the validation set"""

y_pred = decision_tree.predict(X_val)

print("Predictions: ", y_pred[:10])

"""#### Evaluate the model's performance, print classification report and confusion matrix  (10 points)"""

# Evaluate the model performance
conf_matrix = confusion_matrix(y_val, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

print("\nClassification Report:")
print(classification_report(y_val, y_pred))

"""#### Visualize the Decision Tree, show clearly class number, gini value etc.  (10 points)

"""

plt.figure(figsize=(15, 10))
plot_tree(
    decision_tree,
    feature_names=X.columns,
    class_names=decision_tree.classes_.astype(str),
    filled=True,
    impurity=True,
    rounded=True,
)
plt.title("Decision Tree Visualization")
plt.show()

"""### Explain briefly the question. What is the role of gini in decision tree? (10 points)

The Gini Index is a measure of impurity used in decision trees to determine splits. It determines the likelihood of an element selected at random being mislabeled. Purer nodes have lower Gini scores. All samples in a node with Gini = 0 are considered perfectly pure. Gini directs the decision tree to divide at impurity-minimization locations.
"""